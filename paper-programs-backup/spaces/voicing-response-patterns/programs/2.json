{
  "number": 2,
  "originalCode": "// Slider - Smooth Quantitative\n// Keywords: \n// Description: \n\nimportScripts('paper.js');\n\n(async () => {\n\n  const onProgramAdded = ( paperNumber, scratchpad, sharedData ) => {\n    \n      const isFocused = new phet.axon.BooleanProperty(false);\n      phet.paperLand.addModelComponent( 'isFocused', isFocused );\n    \n\n      const nameResponseSmooth = new phet.axon.StringProperty( 'V, Voltage.' );\n      phet.paperLand.addModelComponent( 'nameResponseSmooth', nameResponseSmooth );\n    \n\n      const sizeChangeParameters = new phet.axon.StringProperty( 'shrinks', {\n        validValues: [ 'shrinks', 'grows' ]\n      } );\n      phet.paperLand.addModelComponent( 'sizeChangeParameters', sizeChangeParameters );\n    \n\n      // DerivedProperties are actually implemented with Multilink for now because paper-land has a nice abstraction\n      // for it.\n      const contextResponse = new phet.axon.Property( null );\n      scratchpad.contextResponseDerivedPropertyObserverId = phet.paperLand.addModelPropertyMultilink( [ 'sizeChangeParameters', 'currentValue' ], ( sizeChangeParameters, currentValue ) => {\n        const derivationFunction = () => {\n        \n          // should return a value based on the dependencies\n          const decimalPlaces = 1;\nconst factor = Math.pow(10, decimalPlaces);\nreturn `As letter V ${sizeChangeParameters}, letter I ${sizeChangeParameters}. Current now ${Math.floor(currentValue * factor) / factor} milliamps.`;\n\n        };\n        contextResponse.value = derivationFunction();\n      } );\n      phet.paperLand.addModelComponent( 'contextResponse', contextResponse );\n    \n\n      // DerivedProperties are actually implemented with Multilink for now because paper-land has a nice abstraction\n      // for it.\n      const objectResponseQuantitative = new phet.axon.Property( null );\n      scratchpad.objectResponseQuantitativeDerivedPropertyObserverId = phet.paperLand.addModelPropertyMultilink( [ 'voltageValue' ], ( voltageValue ) => {\n        const derivationFunction = () => {\n        \n          // should return a value based on the dependencies\n          return `${Math.floor(voltageValue)} Volts.`\n        };\n        objectResponseQuantitative.value = derivationFunction();\n      } );\n      phet.paperLand.addModelComponent( 'objectResponseQuantitative', objectResponseQuantitative );\n    \n\n      // Speak whenever the dependencies change.\n      const voiceContextResponsesSpeechFunction = ( contextResponse, objectResponseQuantitative ) => {\n      \n        // get the additional reference constants so they are available in the control function\n        \n      \n        // in a local scope, define the functions that the user can use to manipulate the text\n        \n      const unitBoundsToDisplayBounds = ( bounds ) => {\n        return phet.paperLand.utils.paperToBoardBounds( bounds, sharedData.displaySize.width, sharedData.displaySize.height );\n      };\n      \n      const unitPositionToDisplayPosition = ( position ) => {\n        return phet.paperLand.utils.paperToBoardCoordinates( position, sharedData.displaySize.width, sharedData.displaySize.height );\n      };\n    \n      const setCenterX = ( x ) => {\n        voiceContextResponsesSpeech.centerX = x;\n      };\n      \n      const setCenterY = ( y ) => {\n        voiceContextResponsesSpeech.centerY = y;\n      };\n      \n      const setLeft = ( left ) => {\n        voiceContextResponsesSpeech.left = left;\n      };\n      \n      const setTop = ( top ) => {\n        voiceContextResponsesSpeech.top = top;\n      };\n      \n      const setScale = ( scale ) => {\n        voiceContextResponsesSpeech.setScaleMagnitude( scale );\n      };\n      \n      const setOpacity = ( opacity ) => {\n        voiceContextResponsesSpeech.opacity = opacity;\n      };\n      \n      const setVisible = ( visible ) => {\n        voiceContextResponsesSpeech.visible = visible;\n      };\n      \n      const moveToFront = () => {\n        voiceContextResponsesSpeech.moveToFront();\n      };\n      \n      const moveToBack = () => {\n        voiceContextResponsesSpeech.moveToBack();\n      };\n      \n      const setRotation = ( rotation ) => {\n        voiceContextResponsesSpeech.rotation = rotation;\n      };\n\n      // Set the scale in X and Y and the       \n      const matchBounds = ( bounds, stretch ) => {\n      \n        // Find the scale to apply to the x and y dimensions so that the component bounds match the provided bounds\n        const voiceContextResponsesSpeechViewBounds = phet.paperLand.utils.paperToBoardBounds(bounds, sharedData.displaySize.width, sharedData.displaySize.height);\n\n        // local bounds may be zero as things load\n        // const aspectRatio = ( voiceContextResponsesSpeech.localBounds.width || 1 ) / ( voiceContextResponsesSpeech.localBounds.height || 1 );\n\n        const scaleX = voiceContextResponsesSpeechViewBounds.width / ( voiceContextResponsesSpeech.localBounds.width || 1 );\n        const scaleY = voiceContextResponsesSpeechViewBounds.height / ( voiceContextResponsesSpeech.localBounds.height || 1 );\n\n        if ( stretch ) {\n          voiceContextResponsesSpeech.setScaleMagnitude(scaleX, scaleY);\n        }\n        else {\n        \n          // Scale by the minimum of the x and y scale factors, preserving the aspect ratio\n          voiceContextResponsesSpeech.setScaleMagnitude( Math.min( scaleX, scaleY ) );\n        }        \n\n        // Now put the component in the center of the bounds\n        voiceContextResponsesSpeech.center = voiceContextResponsesSpeechViewBounds.center;\n      };\n      \n\n      \n        // Stop all speech and clear the queue\n        const interruptSpeech = () => {\n          phet.scenery.voicingUtteranceQueue.cancel();;\n        };\n        \n        // Mute/unmute the utterance queue\n        const setMuted = ( v ) => {\n          phet.scenery.voicingUtteranceQueue.setMuted( v );\n        };\n        \n        // Sets the priority of this utterance in the queue\n        const setPriority = ( v ) => {\n          scratchpad.voiceContextResponsesSpeechUtterance.priorityProperty.value = v;\n        }\n        \n        const setAlertStableDelay = ( v ) => {\n          scratchpad.voiceContextResponsesSpeechUtterance.setAlertStableDelay( v );\n        };\n        \n        const setVoiceRate = ( v ) => {\n          phet.scenery.voicingManager.voiceRateProperty.value = v;\n        };\n        \n        const setVoicePitch = ( v ) => {\n          phet.scenery.voicingManager.voicePitchProperty.value = v;\n        };\n      \n      \n        return objectResponseQuantitative + contextResponse\n      }\n      \n      // a reusable utterance for this speech component so that only the latest value is spoken - in general\n      // it should not cancel other Utterances in this context but it should cancel itself\n      scratchpad.voiceContextResponsesSpeechUtterance = new phet.utteranceQueue.Utterance( { announcerOptions: { cancelOther: false } } );\n      \n      scratchpad.voiceContextResponsesSpeechMultilinkId = phet.paperLand.addModelPropertyMultilink( [ 'contextResponse', 'objectResponseQuantitative' ], ( contextResponse, objectResponseQuantitative ) => {\n\n        // Make sure there is a string to speak, including converting falsy values and numbers to a string       \n        const speechResult = voiceContextResponsesSpeechFunction( contextResponse, objectResponseQuantitative );\n        if ( speechResult && speechResult.toString ) {\n          const speechString = speechResult.toString();\n          if ( speechString && speechString.length > 0 ) {\n            scratchpad.voiceContextResponsesSpeechUtterance.alert = speechString;\n            phet.scenery.voicingUtteranceQueue.addToBack( scratchpad.voiceContextResponsesSpeechUtterance ); \n          }\n        }\n      }, {\n        lazy: true,\n        otherReferences: [  ]\n      } ); \n    \n\n      // Speak whenever the dependencies change.\n      const voiceFocusedResponsesSpeechFunction = ( isFocused, nameResponseSmooth, objectResponseQuantitative ) => {\n      \n        // get the additional reference constants so they are available in the control function\n        \n      \n        // in a local scope, define the functions that the user can use to manipulate the text\n        \n      const unitBoundsToDisplayBounds = ( bounds ) => {\n        return phet.paperLand.utils.paperToBoardBounds( bounds, sharedData.displaySize.width, sharedData.displaySize.height );\n      };\n      \n      const unitPositionToDisplayPosition = ( position ) => {\n        return phet.paperLand.utils.paperToBoardCoordinates( position, sharedData.displaySize.width, sharedData.displaySize.height );\n      };\n    \n      const setCenterX = ( x ) => {\n        voiceFocusedResponsesSpeech.centerX = x;\n      };\n      \n      const setCenterY = ( y ) => {\n        voiceFocusedResponsesSpeech.centerY = y;\n      };\n      \n      const setLeft = ( left ) => {\n        voiceFocusedResponsesSpeech.left = left;\n      };\n      \n      const setTop = ( top ) => {\n        voiceFocusedResponsesSpeech.top = top;\n      };\n      \n      const setScale = ( scale ) => {\n        voiceFocusedResponsesSpeech.setScaleMagnitude( scale );\n      };\n      \n      const setOpacity = ( opacity ) => {\n        voiceFocusedResponsesSpeech.opacity = opacity;\n      };\n      \n      const setVisible = ( visible ) => {\n        voiceFocusedResponsesSpeech.visible = visible;\n      };\n      \n      const moveToFront = () => {\n        voiceFocusedResponsesSpeech.moveToFront();\n      };\n      \n      const moveToBack = () => {\n        voiceFocusedResponsesSpeech.moveToBack();\n      };\n      \n      const setRotation = ( rotation ) => {\n        voiceFocusedResponsesSpeech.rotation = rotation;\n      };\n\n      // Set the scale in X and Y and the       \n      const matchBounds = ( bounds, stretch ) => {\n      \n        // Find the scale to apply to the x and y dimensions so that the component bounds match the provided bounds\n        const voiceFocusedResponsesSpeechViewBounds = phet.paperLand.utils.paperToBoardBounds(bounds, sharedData.displaySize.width, sharedData.displaySize.height);\n\n        // local bounds may be zero as things load\n        // const aspectRatio = ( voiceFocusedResponsesSpeech.localBounds.width || 1 ) / ( voiceFocusedResponsesSpeech.localBounds.height || 1 );\n\n        const scaleX = voiceFocusedResponsesSpeechViewBounds.width / ( voiceFocusedResponsesSpeech.localBounds.width || 1 );\n        const scaleY = voiceFocusedResponsesSpeechViewBounds.height / ( voiceFocusedResponsesSpeech.localBounds.height || 1 );\n\n        if ( stretch ) {\n          voiceFocusedResponsesSpeech.setScaleMagnitude(scaleX, scaleY);\n        }\n        else {\n        \n          // Scale by the minimum of the x and y scale factors, preserving the aspect ratio\n          voiceFocusedResponsesSpeech.setScaleMagnitude( Math.min( scaleX, scaleY ) );\n        }        \n\n        // Now put the component in the center of the bounds\n        voiceFocusedResponsesSpeech.center = voiceFocusedResponsesSpeechViewBounds.center;\n      };\n      \n\n      \n        // Stop all speech and clear the queue\n        const interruptSpeech = () => {\n          phet.scenery.voicingUtteranceQueue.cancel();;\n        };\n        \n        // Mute/unmute the utterance queue\n        const setMuted = ( v ) => {\n          phet.scenery.voicingUtteranceQueue.setMuted( v );\n        };\n        \n        // Sets the priority of this utterance in the queue\n        const setPriority = ( v ) => {\n          scratchpad.voiceFocusedResponsesSpeechUtterance.priorityProperty.value = v;\n        }\n        \n        const setAlertStableDelay = ( v ) => {\n          scratchpad.voiceFocusedResponsesSpeechUtterance.setAlertStableDelay( v );\n        };\n        \n        const setVoiceRate = ( v ) => {\n          phet.scenery.voicingManager.voiceRateProperty.value = v;\n        };\n        \n        const setVoicePitch = ( v ) => {\n          phet.scenery.voicingManager.voicePitchProperty.value = v;\n        };\n      \n      \n        if (isFocused) {\n    return nameResponseSmooth + objectResponseQuantitative\n}\n      }\n      \n      // a reusable utterance for this speech component so that only the latest value is spoken - in general\n      // it should not cancel other Utterances in this context but it should cancel itself\n      scratchpad.voiceFocusedResponsesSpeechUtterance = new phet.utteranceQueue.Utterance( { announcerOptions: { cancelOther: false } } );\n      \n      scratchpad.voiceFocusedResponsesSpeechMultilinkId = phet.paperLand.addModelPropertyMultilink( [ 'isFocused', 'nameResponseSmooth', 'objectResponseQuantitative' ], ( isFocused, nameResponseSmooth, objectResponseQuantitative ) => {\n\n        // Make sure there is a string to speak, including converting falsy values and numbers to a string       \n        const speechResult = voiceFocusedResponsesSpeechFunction( isFocused, nameResponseSmooth, objectResponseQuantitative );\n        if ( speechResult && speechResult.toString ) {\n          const speechString = speechResult.toString();\n          if ( speechString && speechString.length > 0 ) {\n            scratchpad.voiceFocusedResponsesSpeechUtterance.alert = speechString;\n            phet.scenery.voicingUtteranceQueue.addToBack( scratchpad.voiceFocusedResponsesSpeechUtterance ); \n          }\n        }\n      }, {\n        lazy: true,\n        otherReferences: [  ]\n      } ); \n    \n  };\n\n  const onProgramRemoved = ( paperNumber, scratchpad, sharedData ) => {\n    \n      // Remove the component from the model\n      phet.paperLand.removeModelComponent( 'isFocused' );\n    \n\n      // Remove the component from the model\n      phet.paperLand.removeModelComponent( 'nameResponseSmooth' );\n    \n\n      // Remove the component from the model\n      phet.paperLand.removeModelComponent( 'sizeChangeParameters' );\n    \n\n\n      // remove the multilink updating the value    \n      phet.paperLand.removeModelPropertyMultilink( [ 'sizeChangeParameters', 'currentValue' ], scratchpad.contextResponseDerivedPropertyObserverId );\n      delete scratchpad.contextResponseDerivedPropertyObserverId;\n      \n      // remove the derived Property from the model\n      phet.paperLand.removeModelComponent( 'contextResponse' );\n    \n\n\n      // remove the multilink updating the value    \n      phet.paperLand.removeModelPropertyMultilink( [ 'voltageValue' ], scratchpad.objectResponseQuantitativeDerivedPropertyObserverId );\n      delete scratchpad.objectResponseQuantitativeDerivedPropertyObserverId;\n      \n      // remove the derived Property from the model\n      phet.paperLand.removeModelComponent( 'objectResponseQuantitative' );\n    \n\n      // Remove the Speech multilink\n      phet.paperLand.removeModelPropertyMultilink( [ 'contextResponse', 'objectResponseQuantitative' ], scratchpad.voiceContextResponsesSpeechMultilinkId, {\n        otherReferences: [  ]\n       } );\n      delete scratchpad.voiceContextResponsesSpeechMultilinkId;\n      \n      // Remove the utterance\n      delete scratchpad.voiceContextResponsesSpeechUtterance;\n    \n\n      // Remove the Speech multilink\n      phet.paperLand.removeModelPropertyMultilink( [ 'isFocused', 'nameResponseSmooth', 'objectResponseQuantitative' ], scratchpad.voiceFocusedResponsesSpeechMultilinkId, {\n        otherReferences: [  ]\n       } );\n      delete scratchpad.voiceFocusedResponsesSpeechMultilinkId;\n      \n      // Remove the utterance\n      delete scratchpad.voiceFocusedResponsesSpeechUtterance;\n    \n  };\n\n  const onProgramChangedPosition = ( paperNumber, points, scratchpad, sharedData ) => {\n    \n    const modelProperty179 = phet.paperLand.getModelComponent( 'voltageValue' );\n    if ( modelProperty179 ) {\n      modelProperty179.value = modelProperty179.range.min + ( 1 - phet.paperLand.utils.getProgramCenter( points ).y ) * ( modelProperty179.range.max - modelProperty179.range.min );\n    }\n\n    const modelProperty180 = phet.paperLand.getModelComponent( 'sizeChangeParameters' );\n    if ( modelProperty180 ) {\n      modelProperty180.value = phet.paperLand.utils.getEnumerationValueFromProgramRotation( points, [\"shrinks\",\"grows\"] );\n    }\n  };\n  \n  const onProgramMarkersAdded = ( paperNumber, points, scratchpad, sharedData, markers ) => {\n    \n  };\n  \n  const onProgramMarkersRemoved = ( paperNumber, points, scratchpad, sharedData, markers ) => {\n    \n  };\n  \n  const onProgramMarkersChangedPosition = ( paperNumber, points, scratchpad, sharedData, markers ) => {\n    \n  };\n  \n  const onProgramAdjacent = ( paperNumber, otherPaperNumber, direction, scratchpad, sharedData ) => {\n    \n    const modelProperty190 = phet.paperLand.getModelComponent( 'isFocused' );\n    if ( modelProperty190 ) {\n      modelProperty190.value = otherPaperNumber === 20;\n    }\n  };\n  \n  const onProgramSeparated = ( paperNumber, otherPaperNumber, direction, scratchpad, sharedData ) => {\n    \n    const modelProperty193 = phet.paperLand.getModelComponent( 'isFocused' );\n    if ( modelProperty193 ) {\n      modelProperty193.value = otherPaperNumber === 20 ? false : modelProperty193.value;\n    }\n  };\n\n  await paper.set( 'data', {\n    paperPlaygroundData: {\n      updateTime: Date.now(),\n      eventHandlers: {\n        onProgramAdded: onProgramAdded.toString(),\n        onProgramRemoved: onProgramRemoved.toString(),\n        onProgramChangedPosition: onProgramChangedPosition.toString(),\n        onProgramMarkersAdded: onProgramMarkersAdded.toString(),\n        onProgramMarkersRemoved: onProgramMarkersRemoved.toString(),\n        onProgramMarkersChangedPosition: onProgramMarkersChangedPosition.toString(),\n        onProgramAdjacent: onProgramAdjacent.toString(),\n        onProgramSeparated: onProgramSeparated.toString(),\n      },\n      customWhiskerLengths: {\n        top: 0.2,\n        right: 0.2,\n        bottom: 0.2,\n        left: 0.2\n      }\n    }\n  } );\n  \n  // PROJECTOR CODE //\n  // Get a canvas object for this paper to draw something to the Projector.\n  const canvas = await paper.get('canvas');\n\n  // Draw the name of the program to the projector\n  const ctx = canvas.getContext('2d');\n  ctx.font = '20px sans-serif';\n  ctx.textAlign = 'center';\n  ctx.fillStyle = 'rgb(255,0,0)';\n  ctx.fillText('', canvas.width / 2, canvas.height / 2 - 10);\n  ctx.fillStyle = 'rgb(0,255,0)';\n  ctx.font = '10px sans-serif';\n  ctx.fillText('Slider - Smooth Quantitative', canvas.width / 2, canvas.height / 2 + 20);\n})();\n",
  "currentCode": "// Slider - Smooth Quantitative\n// Keywords: \n// Description: \n\nimportScripts('paper.js');\n\n(async () => {\n\n  const onProgramAdded = ( paperNumber, scratchpad, sharedData ) => {\n    \n      const isFocused = new phet.axon.BooleanProperty(false);\n      phet.paperLand.addModelComponent( 'isFocused', isFocused );\n    \n\n      const nameResponseSmooth = new phet.axon.StringProperty( 'V, Voltage.' );\n      phet.paperLand.addModelComponent( 'nameResponseSmooth', nameResponseSmooth );\n    \n\n      const sizeChangeParameters = new phet.axon.StringProperty( 'shrinks', {\n        validValues: [ 'shrinks', 'grows' ]\n      } );\n      phet.paperLand.addModelComponent( 'sizeChangeParameters', sizeChangeParameters );\n    \n\n      // DerivedProperties are actually implemented with Multilink for now because paper-land has a nice abstraction\n      // for it.\n      const contextResponse = new phet.axon.Property( null );\n      scratchpad.contextResponseDerivedPropertyObserverId = phet.paperLand.addModelPropertyMultilink( [ 'sizeChangeParameters', 'currentValue' ], ( sizeChangeParameters, currentValue ) => {\n        const derivationFunction = () => {\n        \n          // should return a value based on the dependencies\n          const decimalPlaces = 1;\nconst factor = Math.pow(10, decimalPlaces);\nreturn `As letter V ${sizeChangeParameters}, letter I ${sizeChangeParameters}. Current now ${Math.floor(currentValue * factor) / factor} milliamps.`;\n\n        };\n        contextResponse.value = derivationFunction();\n      } );\n      phet.paperLand.addModelComponent( 'contextResponse', contextResponse );\n    \n\n      // DerivedProperties are actually implemented with Multilink for now because paper-land has a nice abstraction\n      // for it.\n      const objectResponseQuantitative = new phet.axon.Property( null );\n      scratchpad.objectResponseQuantitativeDerivedPropertyObserverId = phet.paperLand.addModelPropertyMultilink( [ 'voltageValue' ], ( voltageValue ) => {\n        const derivationFunction = () => {\n        \n          // should return a value based on the dependencies\n          return `${Math.floor(voltageValue)} Volts.`\n        };\n        objectResponseQuantitative.value = derivationFunction();\n      } );\n      phet.paperLand.addModelComponent( 'objectResponseQuantitative', objectResponseQuantitative );\n    \n\n      // Speak whenever the dependencies change.\n      const voiceContextResponsesSpeechFunction = ( contextResponse, objectResponseQuantitative ) => {\n      \n        // get the additional reference constants so they are available in the control function\n        \n      \n        // in a local scope, define the functions that the user can use to manipulate the text\n        \n      const unitBoundsToDisplayBounds = ( bounds ) => {\n        return phet.paperLand.utils.paperToBoardBounds( bounds, sharedData.displaySize.width, sharedData.displaySize.height );\n      };\n      \n      const unitPositionToDisplayPosition = ( position ) => {\n        return phet.paperLand.utils.paperToBoardCoordinates( position, sharedData.displaySize.width, sharedData.displaySize.height );\n      };\n    \n      const setCenterX = ( x ) => {\n        voiceContextResponsesSpeech.centerX = x;\n      };\n      \n      const setCenterY = ( y ) => {\n        voiceContextResponsesSpeech.centerY = y;\n      };\n      \n      const setLeft = ( left ) => {\n        voiceContextResponsesSpeech.left = left;\n      };\n      \n      const setTop = ( top ) => {\n        voiceContextResponsesSpeech.top = top;\n      };\n      \n      const setScale = ( scale ) => {\n        voiceContextResponsesSpeech.setScaleMagnitude( scale );\n      };\n      \n      const setOpacity = ( opacity ) => {\n        voiceContextResponsesSpeech.opacity = opacity;\n      };\n      \n      const setVisible = ( visible ) => {\n        voiceContextResponsesSpeech.visible = visible;\n      };\n      \n      const moveToFront = () => {\n        voiceContextResponsesSpeech.moveToFront();\n      };\n      \n      const moveToBack = () => {\n        voiceContextResponsesSpeech.moveToBack();\n      };\n      \n      const setRotation = ( rotation ) => {\n        voiceContextResponsesSpeech.rotation = rotation;\n      };\n\n      // Set the scale in X and Y and the       \n      const matchBounds = ( bounds, stretch ) => {\n      \n        // Find the scale to apply to the x and y dimensions so that the component bounds match the provided bounds\n        const voiceContextResponsesSpeechViewBounds = phet.paperLand.utils.paperToBoardBounds(bounds, sharedData.displaySize.width, sharedData.displaySize.height);\n\n        // local bounds may be zero as things load\n        // const aspectRatio = ( voiceContextResponsesSpeech.localBounds.width || 1 ) / ( voiceContextResponsesSpeech.localBounds.height || 1 );\n\n        const scaleX = voiceContextResponsesSpeechViewBounds.width / ( voiceContextResponsesSpeech.localBounds.width || 1 );\n        const scaleY = voiceContextResponsesSpeechViewBounds.height / ( voiceContextResponsesSpeech.localBounds.height || 1 );\n\n        if ( stretch ) {\n          voiceContextResponsesSpeech.setScaleMagnitude(scaleX, scaleY);\n        }\n        else {\n        \n          // Scale by the minimum of the x and y scale factors, preserving the aspect ratio\n          voiceContextResponsesSpeech.setScaleMagnitude( Math.min( scaleX, scaleY ) );\n        }        \n\n        // Now put the component in the center of the bounds\n        voiceContextResponsesSpeech.center = voiceContextResponsesSpeechViewBounds.center;\n      };\n      \n\n      \n        // Stop all speech and clear the queue\n        const interruptSpeech = () => {\n          phet.scenery.voicingUtteranceQueue.cancel();;\n        };\n        \n        // Mute/unmute the utterance queue\n        const setMuted = ( v ) => {\n          phet.scenery.voicingUtteranceQueue.setMuted( v );\n        };\n        \n        // Sets the priority of this utterance in the queue\n        const setPriority = ( v ) => {\n          scratchpad.voiceContextResponsesSpeechUtterance.priorityProperty.value = v;\n        }\n        \n        const setAlertStableDelay = ( v ) => {\n          scratchpad.voiceContextResponsesSpeechUtterance.setAlertStableDelay( v );\n        };\n        \n        const setVoiceRate = ( v ) => {\n          phet.scenery.voicingManager.voiceRateProperty.value = v;\n        };\n        \n        const setVoicePitch = ( v ) => {\n          phet.scenery.voicingManager.voicePitchProperty.value = v;\n        };\n      \n      \n        return objectResponseQuantitative + contextResponse\n      }\n      \n      // a reusable utterance for this speech component so that only the latest value is spoken - in general\n      // it should not cancel other Utterances in this context but it should cancel itself\n      scratchpad.voiceContextResponsesSpeechUtterance = new phet.utteranceQueue.Utterance( { announcerOptions: { cancelOther: false } } );\n      \n      scratchpad.voiceContextResponsesSpeechMultilinkId = phet.paperLand.addModelPropertyMultilink( [ 'contextResponse', 'objectResponseQuantitative' ], ( contextResponse, objectResponseQuantitative ) => {\n\n        // Make sure there is a string to speak, including converting falsy values and numbers to a string       \n        const speechResult = voiceContextResponsesSpeechFunction( contextResponse, objectResponseQuantitative );\n        if ( speechResult && speechResult.toString ) {\n          const speechString = speechResult.toString();\n          if ( speechString && speechString.length > 0 ) {\n            scratchpad.voiceContextResponsesSpeechUtterance.alert = speechString;\n            phet.scenery.voicingUtteranceQueue.addToBack( scratchpad.voiceContextResponsesSpeechUtterance ); \n          }\n        }\n      }, {\n        lazy: true,\n        otherReferences: [  ]\n      } ); \n    \n\n      // Speak whenever the dependencies change.\n      const voiceFocusedResponsesSpeechFunction = ( isFocused, nameResponseSmooth, objectResponseQuantitative ) => {\n      \n        // get the additional reference constants so they are available in the control function\n        \n      \n        // in a local scope, define the functions that the user can use to manipulate the text\n        \n      const unitBoundsToDisplayBounds = ( bounds ) => {\n        return phet.paperLand.utils.paperToBoardBounds( bounds, sharedData.displaySize.width, sharedData.displaySize.height );\n      };\n      \n      const unitPositionToDisplayPosition = ( position ) => {\n        return phet.paperLand.utils.paperToBoardCoordinates( position, sharedData.displaySize.width, sharedData.displaySize.height );\n      };\n    \n      const setCenterX = ( x ) => {\n        voiceFocusedResponsesSpeech.centerX = x;\n      };\n      \n      const setCenterY = ( y ) => {\n        voiceFocusedResponsesSpeech.centerY = y;\n      };\n      \n      const setLeft = ( left ) => {\n        voiceFocusedResponsesSpeech.left = left;\n      };\n      \n      const setTop = ( top ) => {\n        voiceFocusedResponsesSpeech.top = top;\n      };\n      \n      const setScale = ( scale ) => {\n        voiceFocusedResponsesSpeech.setScaleMagnitude( scale );\n      };\n      \n      const setOpacity = ( opacity ) => {\n        voiceFocusedResponsesSpeech.opacity = opacity;\n      };\n      \n      const setVisible = ( visible ) => {\n        voiceFocusedResponsesSpeech.visible = visible;\n      };\n      \n      const moveToFront = () => {\n        voiceFocusedResponsesSpeech.moveToFront();\n      };\n      \n      const moveToBack = () => {\n        voiceFocusedResponsesSpeech.moveToBack();\n      };\n      \n      const setRotation = ( rotation ) => {\n        voiceFocusedResponsesSpeech.rotation = rotation;\n      };\n\n      // Set the scale in X and Y and the       \n      const matchBounds = ( bounds, stretch ) => {\n      \n        // Find the scale to apply to the x and y dimensions so that the component bounds match the provided bounds\n        const voiceFocusedResponsesSpeechViewBounds = phet.paperLand.utils.paperToBoardBounds(bounds, sharedData.displaySize.width, sharedData.displaySize.height);\n\n        // local bounds may be zero as things load\n        // const aspectRatio = ( voiceFocusedResponsesSpeech.localBounds.width || 1 ) / ( voiceFocusedResponsesSpeech.localBounds.height || 1 );\n\n        const scaleX = voiceFocusedResponsesSpeechViewBounds.width / ( voiceFocusedResponsesSpeech.localBounds.width || 1 );\n        const scaleY = voiceFocusedResponsesSpeechViewBounds.height / ( voiceFocusedResponsesSpeech.localBounds.height || 1 );\n\n        if ( stretch ) {\n          voiceFocusedResponsesSpeech.setScaleMagnitude(scaleX, scaleY);\n        }\n        else {\n        \n          // Scale by the minimum of the x and y scale factors, preserving the aspect ratio\n          voiceFocusedResponsesSpeech.setScaleMagnitude( Math.min( scaleX, scaleY ) );\n        }        \n\n        // Now put the component in the center of the bounds\n        voiceFocusedResponsesSpeech.center = voiceFocusedResponsesSpeechViewBounds.center;\n      };\n      \n\n      \n        // Stop all speech and clear the queue\n        const interruptSpeech = () => {\n          phet.scenery.voicingUtteranceQueue.cancel();;\n        };\n        \n        // Mute/unmute the utterance queue\n        const setMuted = ( v ) => {\n          phet.scenery.voicingUtteranceQueue.setMuted( v );\n        };\n        \n        // Sets the priority of this utterance in the queue\n        const setPriority = ( v ) => {\n          scratchpad.voiceFocusedResponsesSpeechUtterance.priorityProperty.value = v;\n        }\n        \n        const setAlertStableDelay = ( v ) => {\n          scratchpad.voiceFocusedResponsesSpeechUtterance.setAlertStableDelay( v );\n        };\n        \n        const setVoiceRate = ( v ) => {\n          phet.scenery.voicingManager.voiceRateProperty.value = v;\n        };\n        \n        const setVoicePitch = ( v ) => {\n          phet.scenery.voicingManager.voicePitchProperty.value = v;\n        };\n      \n      \n        if (isFocused) {\n    return nameResponseSmooth + objectResponseQuantitative\n}\n      }\n      \n      // a reusable utterance for this speech component so that only the latest value is spoken - in general\n      // it should not cancel other Utterances in this context but it should cancel itself\n      scratchpad.voiceFocusedResponsesSpeechUtterance = new phet.utteranceQueue.Utterance( { announcerOptions: { cancelOther: false } } );\n      \n      scratchpad.voiceFocusedResponsesSpeechMultilinkId = phet.paperLand.addModelPropertyMultilink( [ 'isFocused', 'nameResponseSmooth', 'objectResponseQuantitative' ], ( isFocused, nameResponseSmooth, objectResponseQuantitative ) => {\n\n        // Make sure there is a string to speak, including converting falsy values and numbers to a string       \n        const speechResult = voiceFocusedResponsesSpeechFunction( isFocused, nameResponseSmooth, objectResponseQuantitative );\n        if ( speechResult && speechResult.toString ) {\n          const speechString = speechResult.toString();\n          if ( speechString && speechString.length > 0 ) {\n            scratchpad.voiceFocusedResponsesSpeechUtterance.alert = speechString;\n            phet.scenery.voicingUtteranceQueue.addToBack( scratchpad.voiceFocusedResponsesSpeechUtterance ); \n          }\n        }\n      }, {\n        lazy: true,\n        otherReferences: [  ]\n      } ); \n    \n  };\n\n  const onProgramRemoved = ( paperNumber, scratchpad, sharedData ) => {\n    \n      // Remove the component from the model\n      phet.paperLand.removeModelComponent( 'isFocused' );\n    \n\n      // Remove the component from the model\n      phet.paperLand.removeModelComponent( 'nameResponseSmooth' );\n    \n\n      // Remove the component from the model\n      phet.paperLand.removeModelComponent( 'sizeChangeParameters' );\n    \n\n\n      // remove the multilink updating the value    \n      phet.paperLand.removeModelPropertyMultilink( [ 'sizeChangeParameters', 'currentValue' ], scratchpad.contextResponseDerivedPropertyObserverId );\n      delete scratchpad.contextResponseDerivedPropertyObserverId;\n      \n      // remove the derived Property from the model\n      phet.paperLand.removeModelComponent( 'contextResponse' );\n    \n\n\n      // remove the multilink updating the value    \n      phet.paperLand.removeModelPropertyMultilink( [ 'voltageValue' ], scratchpad.objectResponseQuantitativeDerivedPropertyObserverId );\n      delete scratchpad.objectResponseQuantitativeDerivedPropertyObserverId;\n      \n      // remove the derived Property from the model\n      phet.paperLand.removeModelComponent( 'objectResponseQuantitative' );\n    \n\n      // Remove the Speech multilink\n      phet.paperLand.removeModelPropertyMultilink( [ 'contextResponse', 'objectResponseQuantitative' ], scratchpad.voiceContextResponsesSpeechMultilinkId, {\n        otherReferences: [  ]\n       } );\n      delete scratchpad.voiceContextResponsesSpeechMultilinkId;\n      \n      // Remove the utterance\n      delete scratchpad.voiceContextResponsesSpeechUtterance;\n    \n\n      // Remove the Speech multilink\n      phet.paperLand.removeModelPropertyMultilink( [ 'isFocused', 'nameResponseSmooth', 'objectResponseQuantitative' ], scratchpad.voiceFocusedResponsesSpeechMultilinkId, {\n        otherReferences: [  ]\n       } );\n      delete scratchpad.voiceFocusedResponsesSpeechMultilinkId;\n      \n      // Remove the utterance\n      delete scratchpad.voiceFocusedResponsesSpeechUtterance;\n    \n  };\n\n  const onProgramChangedPosition = ( paperNumber, points, scratchpad, sharedData ) => {\n    \n    const modelProperty179 = phet.paperLand.getModelComponent( 'voltageValue' );\n    if ( modelProperty179 ) {\n      modelProperty179.value = modelProperty179.range.min + ( 1 - phet.paperLand.utils.getProgramCenter( points ).y ) * ( modelProperty179.range.max - modelProperty179.range.min );\n    }\n\n    const modelProperty180 = phet.paperLand.getModelComponent( 'sizeChangeParameters' );\n    if ( modelProperty180 ) {\n      modelProperty180.value = phet.paperLand.utils.getEnumerationValueFromProgramRotation( points, [\"shrinks\",\"grows\"] );\n    }\n  };\n  \n  const onProgramMarkersAdded = ( paperNumber, points, scratchpad, sharedData, markers ) => {\n    \n  };\n  \n  const onProgramMarkersRemoved = ( paperNumber, points, scratchpad, sharedData, markers ) => {\n    \n  };\n  \n  const onProgramMarkersChangedPosition = ( paperNumber, points, scratchpad, sharedData, markers ) => {\n    \n  };\n  \n  const onProgramAdjacent = ( paperNumber, otherPaperNumber, direction, scratchpad, sharedData ) => {\n    \n    const modelProperty190 = phet.paperLand.getModelComponent( 'isFocused' );\n    if ( modelProperty190 ) {\n      modelProperty190.value = otherPaperNumber === 20;\n    }\n  };\n  \n  const onProgramSeparated = ( paperNumber, otherPaperNumber, direction, scratchpad, sharedData ) => {\n    \n    const modelProperty193 = phet.paperLand.getModelComponent( 'isFocused' );\n    if ( modelProperty193 ) {\n      modelProperty193.value = otherPaperNumber === 20 ? false : modelProperty193.value;\n    }\n  };\n\n  await paper.set( 'data', {\n    paperPlaygroundData: {\n      updateTime: Date.now(),\n      eventHandlers: {\n        onProgramAdded: onProgramAdded.toString(),\n        onProgramRemoved: onProgramRemoved.toString(),\n        onProgramChangedPosition: onProgramChangedPosition.toString(),\n        onProgramMarkersAdded: onProgramMarkersAdded.toString(),\n        onProgramMarkersRemoved: onProgramMarkersRemoved.toString(),\n        onProgramMarkersChangedPosition: onProgramMarkersChangedPosition.toString(),\n        onProgramAdjacent: onProgramAdjacent.toString(),\n        onProgramSeparated: onProgramSeparated.toString(),\n      },\n      customWhiskerLengths: {\n        top: 0.2,\n        right: 0.2,\n        bottom: 0.2,\n        left: 0.2\n      }\n    }\n  } );\n  \n  // PROJECTOR CODE //\n  // Get a canvas object for this paper to draw something to the Projector.\n  const canvas = await paper.get('canvas');\n\n  // Draw the name of the program to the projector\n  const ctx = canvas.getContext('2d');\n  ctx.font = '20px sans-serif';\n  ctx.textAlign = 'center';\n  ctx.fillStyle = 'rgb(255,0,0)';\n  ctx.fillText('', canvas.width / 2, canvas.height / 2 - 10);\n  ctx.fillStyle = 'rgb(0,255,0)';\n  ctx.font = '10px sans-serif';\n  ctx.fillText('Slider - Smooth Quantitative', canvas.width / 2, canvas.height / 2 + 20);\n})();\n",
  "printed": false,
  "editorInfo": {},
  "currentCodeUrl": "program.voicing-response-patterns.2.js",
  "currentCodeHash": "",
  "debugUrl": "/api/spaces/voicing-response-patterns/programs/2/debugInfo",
  "claimUrl": "/api/spaces/voicing-response-patterns/programs/2/claim",
  "codeHasChanged": false,
  "debugInfo": "{\"logs\":[]}"
}